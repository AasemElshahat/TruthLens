\bibliographystyle{apalike}
\bibliography{references} % This points to the file named references.bib

% --- METHODOLOGY & FRAMEWORKS ---

@article{SAFE2024,
  title={Long-form factuality in large language models},
  author={Wei, Jerry and Huang, Jie and Yang, Chengrun and others},
  journal={arXiv preprint arXiv:2403.18802},
  year={2024},
  note={Available at: \url{https://arxiv.org/abs/2403.18802} (Accessed: 2025-10-12). The SAFE Framework paper}
}

@article{Metropolitansky2025,
  title={Towards Effective Extraction and Evaluation of Factual Claims},
  author={Metropolitansky, Dasha and Larson, Jonathan},
  journal={arXiv preprint arXiv:2502.10855},
  year={2025},
  note={Available at: \url{https://arxiv.org/abs/2502.10855} (Accessed: 2025-11-05). The Claimify Paper}
}

@article{BingCheck,
  title={Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models},
  author={Li, Miaoran and Peng, Baolin and Galley, Michel and Gao, Jianfeng and Zhang, Zhu},
  journal={Findings of the Association for Computational Linguistics: NAACL 2024},
  year={2024},
  note={Available at: \url{https://aclanthology.org/2024.findings-naacl.156/} (Accessed: 2025-10-20). Original creators of the BingCheck dataset}
}

% --- THEORETICAL BACKGROUND ---

@article{Ji2023Survey,
  title={Survey of hallucination in large language models},
  author={Ji, Ziwei and others},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  year={2023},
  publisher={ACM New York, NY},
  note={Standard survey paper defining Hallucinations (Intrinsic/Extrinsic)}
}

@article{Huang2024Survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and others},
  journal={ACM Transactions on Information Systems},
  volume={1},
  number={1},
  year={2024},
  publisher={ACM New York, NY},
  note={Defines Factuality vs. Faithfulness Hallucinations}
}

@article{Wang2024Agents,
  title={A Survey on Large Language Model based Autonomous Agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  publisher={Springer},
  doi={10.1007/s11704-024-40231-1},
  note={Defines the unified framework for LLM-based agents}
}

@inproceedings{LLMJudge,
  title={Judging {LLM}-as-a-judge with {MT}-Bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023},
  note={Standard citation for the LLM-as-a-Judge concept}
}

@inproceedings{FEVER,
  title={{FEVER}: a large-scale dataset for Fact Extraction and {VERification}},
  author={Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year={2018},
  note={Standard citation for traditional fact-checking pipelines}
}

@article{Cheng2024,
  title={Dated Data: Tracing Knowledge Cutoffs in Large Language Models},
  author={Cheng, Jeffrey and Marone, Marc and Weller, Orion and Lawrie, Dawn and Khashabi, Daniel and Van Durme, Benjamin},
  journal={arXiv preprint arXiv:2403.12958},
  year={2024},
  note={Available at: \url{https://arxiv.org/abs/2403.12958} (Accessed: 2025-10-25). Analysis of static knowledge limitations in LLMs}
}

@book{Gamma1994,
  title={Design Patterns: Elements of Reusable Object-Oriented Software},
  author={Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
  year={1994},
  publisher={Addison-Wesley},
  note={The definitive reference for the Strategy Pattern}
}


% --- SELF-CORRECTION & HALLUCINATION MITIGATION ---

@inproceedings{Dhuliawala2024CoVe,
  title={Chain-of-Verification Reduces Hallucination in Large Language Models},
  author={Dhuliawala, Shehzaad and Komeili, Mojtaba and Xu, Jing and Raileanu, Roberta and Li, Xian and Celikyilmaz, Asli and Weston, Jason},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2024},
  pages={3563--3578},
  year={2024},
  note={Chain-of-Verification (CoVe) method for self-correction in LLMs}
}

@article{Varshney2023,
  title={A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of {LLMs} by Validating Low-Confidence Generation},
  author={Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
  journal={arXiv preprint arXiv:2307.03987},
  year={2023},
  note={Available at: \url{https://arxiv.org/abs/2307.03987} (Accessed: 2025-11-10). Confidence-based hallucination detection}
}

@inproceedings{Pan2024CAG,
  title={Not All Contexts Are Equal: Teaching {LLMs} Credibility-aware Generation},
  author={Pan, Ruotong and Cao, Boxi and Lin, Hongyu and Han, Xianpei and Zheng, Jia and Wang, Sirui and Cai, Xunliang and Sun, Le},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={19873--19889},
  year={2024},
  note={Credibility-aware Generation (CAG) for evidence quality assessment}
}

% --- SOFTWARE & REPOSITORIES ---

@misc{ClaimeAI_Repo,
  author = {BharathxD},
  title = {{ClaimeAI}: Open Source Fact-Checking Pipeline},
  year = {2024},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/BharathxD/ClaimeAI}},
  note = {(Accessed: 2025-10-15). The baseline architecture adapted for the TruthLens framework}
}

@misc{LangGraph,
  author = {{LangChain AI}},
  title = {{LangGraph}: Building Stateful Multi-Actor Applications with {LLMs}},
  year = {2024},
  howpublished = {\url{https://langchain-ai.github.io/langgraph/}},
  note = {(Accessed: 2025-11-02). Graph-based orchestration framework for agentic workflows}
}

@misc{Pydantic,
  author = {Colvin, Samuel and others},
  title = {Pydantic: Data Validation using Python Type Hints},
  year = {2024},
  howpublished = {\url{https://docs.pydantic.dev/}},
  note = {(Accessed: 2025-10-28). Data validation library used for structured output enforcement}
}

@misc{BraveSearchAPI,
  title = {Brave Search {API}},
  author = {{Brave Software}},
  year = {2024},
  howpublished = {\url{https://brave.com/search/api/}},
  note = {(Accessed: 2025-11-20)}
}

% --- MODEL TECHNICAL REPORTS ---

@article{Gemini25,
  title={Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities},
  author={{Gemini Team, Google}},
  journal={arXiv preprint arXiv:2507.06261},
  year={2025},
  note={Available at: \url{https://arxiv.org/abs/2507.06261} (Accessed: 2025-12-05). Technical Report for Gemini 2.5 Flash}
}

@article{DeepSeekV3.2,
  title={{DeepSeek-V3.2}: Pushing the Frontier of Open Large Language Models},
  author={{DeepSeek-AI}},
  journal={arXiv preprint arXiv:2512.02556},
  year={2025},
  note={Available at: \url{https://arxiv.org/abs/2512.02556} (Accessed: 2025-12-28). Technical Report for DeepSeek-V3.2}
}

@misc{GPT4omini,
  title={{GPT-4o mini}: Advancing Cost-Efficient Intelligence},
  author={{OpenAI}},
  year={2024},
  howpublished={\url{https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/}},
  note={(Accessed: 2025-12-09)}
}